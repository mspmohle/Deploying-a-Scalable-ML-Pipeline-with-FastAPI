Model Details

Project: D501 – Deploying a Scalable ML Pipeline with FastAPI

Task: Binary classification — predict income ( >50K vs <=50K ) from census features

Algorithm: RandomForestClassifier (scikit-learn 1.5.1)

Key params: n_estimators=200, random_state=42, n_jobs=-1 (others default)

Preprocessing:

Categorical: OneHotEncoder(handle_unknown="ignore", sparse_output=False) on
workclass, education, marital-status, occupation, relationship, race, sex, native-country

Target: LabelBinarizer on salary (<=50K/>50K)

Artifacts: model/model.joblib, model/encoder.joblib, model/lb.joblib

Environment: Python 3.10; packages pinned in requirements.txt

Serving: FastAPI app (main.py) with endpoints:

GET /health → readiness

POST /predict → JSON input, returns prediction and prob_gt_50k

Intended Use

Primary: Educational demonstration of an end-to-end ML workflow (training, testing, serving via REST).

Not intended for: Production or high-stakes individual decision making.

API Input: Single-record JSON with fields (aliases supported):
age, fnlgt, education, education-num, workclass, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country.

Training Data

Dataset: Adult Census Income (data/census.csv) from the UCI/“Adult” dataset family.

Features:

Numerical: age, fnlgt, education-num, capital-gain, capital-loss, hours-per-week

Categorical: workclass, education, marital-status, occupation, relationship, race, sex, native-country

Split: 80/20 train/test (stratified by target).

Evaluation Data

Held-out test set: 20% of the original dataset (stratified).

Preprocessing at inference: Same encoders as training (saved in model/).

Thresholding: Native classifier decision rule (RF class prediction; predict_proba reported as prob_gt_50k).

Metrics

Please include the metrics used and your model's performance on those metrics.

Overall (test set):

Precision: 0.734

Recall: 0.636

F1 (β=1): 0.682

Slice metrics: Per-category precision/recall/F1 across each categorical feature.

See screenshot/slice_output.txt for full table (generated by train_model.py).

Use these to identify groups with notably lower performance (e.g., by sex, race, native-country, education, etc.).

Ethical Considerations

Representation & Bias: Historical income data encodes labor-market inequities. Model performance may vary across demographic groups; false positives/negatives can be unevenly distributed.

Fairness Risks: Using predictions for real decisions could reinforce disparities. Always review slice metrics and consider fairness interventions (reweighting, thresholds per group, calibrated models, or fairness-aware algorithms).

Privacy: Data contain personal attributes; ensure proper handling and avoid unintended re-identification when sharing any outputs.

Transparency: Document model intent (educational), training data vintage, and limitations to prevent misuse.

Caveats and Recommendations

Generalization: Trained on a specific, historic dataset; distribution drift will degrade performance.

Unseen Categories: OneHotEncoder(handle_unknown="ignore") drops unseen categories at inference; monitor for frequent unknowns.

Calibration: Random forests may be poorly calibrated; if probabilistic decisions matter, add calibration (e.g., CalibratedClassifierCV).

Monitoring: Track input drift, target drift, and key metrics over time; re-train on fresh data when drift is detected.
